# new TODO: Remove/delete `need`ing _debug and _log except at the very start
---
metadata:
  title: |
    ALKiln in the Playground
  short title: |
    ALKiln
  description: |
    Run ALKiln tests on your server. No GitHub required.
  under: |
    See guides for writing tests in the [ALKiln documentation](https://suffolklitlab.org/docassemble-AssemblyLine-documentation/docs/automated_integrated_testing).
---
include:
  - artifacts.yml
---
comment: |
  - Stop tests early: console output should show that tests were stopped early
---
features:
  css: alkiln_playground.css
---
mandatory: True
id: interview order
need:
  - _log
  - _debug
code: |
  if not user_has_privilege(['admin', 'developer']):
    ask_to_log_in
  
  if len(dangerous_config_var_names) > 0:
    warn_about_dangerous_config_vars
  
  if redo_after_stopped_with_invalid_install:
    invalid_install = True
    undefine_install_task = True
    require_restart_install_timer = True
    undefine('ask_version')
    undefine('install_failed')
    redo_after_stopped_with_invalid_install = False
  
  if undefine_install_task:
    undefine('install_task')
    undefine_install_task = False
  
  if version_error == '':
    ask_version
    if wants_install or invalid_install:
      # Don't install if not needed
      if started_with_different_version or invalid_install:
        install_task
        # `.wait()` could cause a timeout
        if install_task.ready():
          if install_task.failed():
            # If failed after invalid install, even if it was a different failure, start again again. After an invalid install, it _really_ has to be sure to install.
            if invalid_install:
              redo_after_stopped_with_invalid_install = True
            # Otherwise just show a failure message
            else:
              invalid_install = False
              flag_failed_installation
          else:
            invalid_install = False
        else:
          if require_restart_install_timer:
            restart_install_timer
          wait_for_install
    
  not_wants_tags
  tag_expression

  if (
    ( artifacts_folder_and_runtime_config_final_status == 'done' and artifacts_errored )
  ):
    setup_errored = True
  else:
    setup_errored = False  
  
  if setup_errored:
    _debug('One of the setup steps errored')
    # If we expect ALKiln to have the necessary scripts then
    # show the error on final screen
    # (Note: We delete the original files after showing the output
    # screen)
    show_output  # terminating screen

  _debug('Running alkiln tests')
  test_run_output
  
  test_run_output
  if stopped_early or test_run_output.ready():
    _debug(f'stopped_early: { stopped_early }')
    run_get_files_html
    # We remove the original files after showing the output screen
    show_output
  else:
    waiting_screen

  show_output
---
code: |
  end_time = current_datetime()
---
code: |
  setup_outputs = []
---
code: |
  if get_config('s3').get('enable'):
    sources = f'/tmp/playgroundsources/{user_info().id}/{project_name}'
  else:
    sources = f'/usr/share/docassemble/files/playgroundsources/{user_info().id}/{project_name}'
---
####################################
# Blockers
####################################
---
event: ask_to_log_in
id: not logged in
question: |
  You need to log in as a developer
subquestion: |
  To run these tests, you need to be logged into the server where you're keeping the package that you will test. You must be logged in as a developer or an admin.
buttons:
  Log into this server: signin
---
id: dangerous config var warning
if: len(dangerous_config_var_names) > 0
event: warn_about_dangerous_config_vars
question: |
  Before you start, you must change your `alkiln` config keys
subquestion: |
  In <a target="_blank" href="${url_of('root', _external=True)}/config">your docassemble server config</a>'s `alkiln` keys, you have used ${ 'variable names' if len(dangerous_config_var_names) > 1 else 'a variable name' } that your operating system is already using:
  
  % if len(dangerous_config_var_names) > 1:
  % for name in dangerous_config_var_names:
  * ${ name }
  % endfor
  % else:
  ${ dangerous_config_var_names[0] }
  % endif
  
  To fix this:
  
  % if len(dangerous_config_var_names) > 1:
  - Change these names to something else in your config. Starting these types of variable names with something unique, like "ALKILN_", might help keep your variable names safe.
  - Update the names in your tests.
  % else:
  - Change this name to something else in your config. Starting the variable name with something unique, like "ALKILN_", might help keep your variable name safe.
  - Update the name in your tests.
  % endif
  
  When you have done that, restart.
  
buttons:
  - ":undo: Restart": restart
---
####################################
# Installation
####################################
---
event: stop_install_early
code: |
  redo_after_stopped_with_invalid_install = True
  install_task.revoke()
---
code: |
  redo_after_stopped_with_invalid_install = False
---
code: |
  invalid_install = False
---
code: |
  undefine_install_task = False
---
code: |
  import subprocess
  import json
  
  def filter_versions_greater_or_equal(versions, minimum="0.0.0"):
    '''Given a list of strings of versions, return a new list of
    versions at or above the given minimum version.'''
    major_versions = []
    pre_versions = []
    try:
      minimum = [int(s) for s in minimum.split(".", maxsplit=2)]
    except Exception as err:
      raise ValueError(f"■■■ ALKiln Error ALKP0001: npm version filter expected a version string in the form major.minor.patch, but got {minimum}") from err
    for version in versions:
      maj, minor, patch_and_prelease, = version.split(".", maxsplit=2)
      # If there is a prerelease attached, get rid of it in 
      # order to make the comparison
      if "-" in patch_and_prelease:
        patch, pre = patch_and_prelease.split("-", maxsplit=1)
        version_parts = [int(maj), int(minor), int(patch)]
        if version_parts >= minimum:
            pre_versions.append(version)
      else:
        version_parts = [int(maj), int(minor), int(patch_and_prelease)]
        if version_parts >= minimum:
            major_versions.append(version)
    return { "major": major_versions, "pre": pre_versions }
  
  # all versions, but not working: https://stackoverflow.com/a/41416032/14144258
  # puzzle of above: @>4.0.0 seems to get all versions @>5.0.0 seems to get none (only have a single pre-release right now). When none are found, we get err 'JSONDecodeError: Expecting value: line 1 column 1 (char 0)'
  result = subprocess.run(['npm', 'view', "@suffolklitlab/alkiln", 'versions', '--json'], check=False, capture_output=True)
  if result.returncode != 0:
    log('■■■ ALKiln Error ALKP0002: npm install error getting ALKiln versions:')
    log(result.stderr.decode("utf-8"))
    alkiln_version_list = []
    alkiln_major_versions = []
    alkiln_prerelease_versions = []
    version_error = result.stderr.decode("utf-8")
  else:
    versions = json.loads(result.stdout.decode())
    filtered = filter_versions_greater_or_equal(reversed(versions), '5.0.0')
    alkiln_major_versions = filtered[ "major" ]
    alkiln_prerelease_versions = filtered[ "pre" ]
    alkiln_version_list = []
    version_error = ''
---
id: which task with no alkiln installed
if: |
  'Could not get' in get_installed_version() or invalid_install
need:
  - get_installed_version
  - invalid_install
question: |
  Install ALKiln
subquestion: |
  It looks like you either don't have ALKiln installed yet or you need to install a new version for another reason. For example, someone may have started installing a version and then cancelled installing the version. You need a new version of ALKiln.
  
  Which version of ALKiln do you want to install? The top choice is the most recent version. While it is installing you will have to avoid the following:
  
  - Saving a python module
  - Pulling or uploading a package with a python module
  - Otherwise causing the server to reload, restart, or stop
fields:
  - Install a different verison of ALKiln: wants_install
    datatype: yesno
  - ALKiln version: version_to_install
    js show if:
      val('wants_install') && !val('wants_experimental')
    choices:
      code: |
        alkiln_major_versions
  - Install an experimental version instead: wants_experimental
    datatype: yesno
    show if: wants_install
  - Experimental ALKiln version: version_to_install
    show if: wants_experimental
    choices:
      code: |
        alkiln_prerelease_versions
continue button field: ask_version
validation code: |
  if not wants_install:
    validation_error('You must install a version of ALKiln')
---
id: which task with prexisting version
if: |
  not 'Could not get' in get_installed_version() and not invalid_install
need:
  - invalid_install
  - get_installed_version
question: |
  ALKiln version
subquestion: |
  The server's current version of ALKiln is:[BR]
  **${ get_installed_version() }**
  
  Do you want to install a different version of ALKiln before testing? **While it is installing you will have to avoid the following**:
  
  - Saving a python module
  - Pulling or uploading a package with a python module
  - Otherwise causing the server to reload, restart, or stop
  
fields:
  - Install a different verison of ALKiln: wants_install
    datatype: yesno
  - ALKiln version: version_to_install
    js show if:
      val('wants_install') && !val('wants_experimental')
    choices:
      code: |
        alkiln_major_versions
  - Install an experimental version instead: wants_experimental
    datatype: yesno
    show if: wants_install
  - Experimental ALKiln version: version_to_install
    show if: wants_experimental
    choices:
      code: |
        alkiln_prerelease_versions
continue button field: ask_version
---
code: |
  wants_install = True
---
code: |
  if version_to_install != get_installed_version():
    started_with_different_version = True
  else:
    started_with_different_version = False
---
# new TODO: Delete old code
# new TODO: Discuss better way to indicate failure (as opposed to message strings)
# new TODO: Should `if matches == None:` be an error path?
# new TODO: Improve error logs
need:
  - _log
code: |
  import subprocess
  import re
  
  def get_installed_version():
    '''Returns string to print for the version number.
       Can be some kind of error message with 'Could not get'.'''

    # https://stackoverflow.com/a/13332300
    packages = subprocess.run(['npm', 'list', '-g', '--prefix', '/var/www/.npm-global', '--depth', '0', '-p', '-l'], check=False, capture_output=True)
    # What would cause an error here?
    if packages.returncode != 0:
      _log('🤕 ALKiln Error ALKP0003: getting this server\'s currently installed ALKiln version:')
      _log(f'Error code: { packages.returncode }')
      _log( packages.stderr.decode("utf-8") )
      server_version = "Could not get this server's version of ALKiln. ALKilnInThePlayground got an error instead."
    else:
      pattern = re.compile(r'suffolklitlab/alkiln@(\d.*)$')
      matches = re.search(pattern, packages.stdout.decode())
      if matches == None:
        server_version = "This server's version of ALKiln seems to be missing. Install a version of ALKiln to continue."
      else:
        server_version = matches.group(1)
        del matches # cannot pickle error otherwise
    return server_version
---
code: |
  install_task = background_action('install_alkiln', None, version=version_to_install)
---
event: install_alkiln
code: |
  import subprocess
  import os
  
  # TODO: How do we detect if someone _else_ on the server didn't properly finish installing ALKiln and that there will be non-cache problems?
  
  subprocess.run(['mkdir', '-p', '/var/www/.npm-global'])
  
  # Must install with npm version, not GitHub branch as
  # we don't know a simple way to get the npm version from the
  # branch installation so we can help the user install the
  # right version or, alternatively, avoid installing anything
  # unecessary. On GitHub, though, we hope to use the branch
  # or commit as the source of truth for our version. This
  # unfortunately means there can't be just one source of truth
  # for which version of ALKiln is being used.
  
  # if statement for idempotency? Run install only once. Needed here?
  if not did_install:
    to_install = f'@suffolklitlab/alkiln@{action_argument("version")}'
    install_output = subprocess.run(['npm', 'install', '-g', to_install], check=False, capture_output=True, env=dict(os.environ, NPM_CONFIG_PREFIX="/var/www/.npm-global"))
    did_install = True
  
  if install_output.returncode != 0:
    result = install_output.stderr.decode('utf-8')
    log(f'■■■ ALKiln Error ALKP0004: installing ALKiln version {action_argument("version")} failed')
    log(result)
    
    # Should this be a default behavior with any error?
    if 'ENOTEMPTY' in result:
      # When tested, returned non-zero exit status 217 was the logged subprocess err
      
      log('□□□ ALKiln: Trying to clean up the old ALKiln installation.')
      # https://stackoverflow.com/a/72022642
      delete_kiln_output = subprocess.run(['rm', '-r', '/var/www/.npm-global/lib/node_modules/@suffolklitlab'], check=False, capture_output=True)
      
      # Do we need an idempotency flag here?
      log(f'□□□ ALKiln: Trying to install version {action_argument("version")} again.')
      install_output = subprocess.run(['npm', 'install', '-g', to_install], check=False, capture_output=True, env=dict(os.environ, NPM_CONFIG_PREFIX="/var/www/.npm-global"))
      
      # Not sure what more we can do at this point if it goes wrong
      if install_output.returncode != 0:
        log(f'■■■ ALKiln Error ALKP0005: 2nd time installing version {action_argument("version")} failed')
        log(install_output.stderr.decode('utf-8'))
        
  # Always except if is still an error. Will cause failure.
  install_output.check_returncode()
  
  # If no error thrown by now, log output and succeed
  result = install_output.stdout.decode('utf-8')
  log('□□□ ALKiln Installation succeeded:')
  log(result)

  background_response(result)
---
code: |
  did_install = False
---
code: |
  install_failed = True
  flag_failed_installation = True
---
code: |
  install_failed = False
---
id: wait for alkiln install
prevent going back: True
reload: True
event: wait_for_install
question: |
  One sec, installing ALKiln v${version_to_install}
subquestion: |
  <div class="spinner-container d-flex justify-content-center">
  <div class="spinner-border" role="status">
    <span class="visually-hidden">Installing...</span>
  </div>
  </div>

  **While ALKiln is installing DO NOT:**
  
  - Save a python module
  - Pull or upload a package with a python module
  - Otherwise cause the server to reload, restart, or stop
  
  This should take less than a minute, though if your server or the npm servers are slow, it may take longer.
  
  **Elapsed time: ${ str(date_difference( ending=current_datetime(), starting=install_start ).delta) }**[BR]
  (Updates about every 10 seconds depending on your server)

# revoke install
action buttons:
  - label: Cancel and try again
    action: stop_install_early
    icon: window-close
    color: danger
---
# TODO: Explore these install_timer blocks
code: |
  require_restart_install_timer = False
---
event: restart_install_timer
code: |
  require_restart_install_timer = False
  install_start = current_datetime()
---
code: |
  install_start = current_datetime()
---
####################################
# Testing
####################################
---
id: test info
prevent going back: True
question: |
  Run ALKiln tests
subquestion: |
  % if install_failed:
  <p class="alert alert-warning">
  Warning: ALKiln installation failed. You can still run your tests with the previous version you had installed. To see more, check <a target="_blank" href="${url_of('root', _external=True)}/logs?file=worker.log">your worker.log</a>. It might have been a problem with the node package manager (npm) servers. The <a href="https://status.npmjs.org/">npm status page</a> might tell you if npm servers are down. If you want to use a different version of ALKiln, you'll have to try again later.
  </p>
  % endif

  % if version_error != '':
  <p class="alert alert-warning">
  Warning: Usually you would have seen an option to install a different version of ALKiln. We skipped that screen because there was a problem getting information from the npm servers. You can check the output of the error in <a target="_blank" href="${url_of('root', _external=True)}/logs?file=docassemble.log">your docassemble.log</a>. It might have been a problem with the node package manager (npm) servers. The <a href="https://status.npmjs.org/">npm status page</a> might tell you if npm servers are down. If you want to use a different version of ALKiln, you'll have to try again later.
  </p>
  % endif
  
  You will run your tests with this version of ALKiln:[BR]
  **${ get_installed_version() }**
  
  While tests are running try to avoid:
  
  - Editing this project
  - Saving a python module
  - Pulling or uploading a package with a python module
  - Causing the server to reload, restart, or stop
fields:
  - note: |
      The code you want to test should be in a Project on your Playground on this server.
  - What Project is the code in?: project_name
    input type: radio
    choices:
      code: |
        [[ proj, proj ] for proj in get_list_of_projects( user_info().id )]
  - note: |
      You can choose to run just specific tests using [tags](https://cucumber.io/docs/cucumber/api/?lang=java#tags) in your test file and putting a [tag expression](https://cucumber.io/docs/cucumber/api/#tag-expressions) below.
  - I want to run all the tests: not_wants_tags
    datatype: yesno
  - Your tag expression: tag_expression
    disable if: not_wants_tags
    # Doesn't matter if they leave it blank
    required: False
continue button label: '<i class="far fa-play-circle"></i> Run tests'
action buttons:
  - label: Restart
    action: do_restart
    icon: undo
    color: warning
---
event: do_restart
code: |
  command('restart')
---
code: |
  from docassemble.webapp.files import SavedFile
  from docassemble.webapp.backend import directory_for
  import os

  def get_list_of_projects(user_id):
    playground = SavedFile(user_id, fix=False, section='playground')
    return playground.list_of_dirs()
---
if:
  - not_wants_tags
code: |
  tag_expression = ''
---
code: |
  test_run_output = background_action('run_alkiln', None, tag_expression=tag_expression, project_name=project_name)
---
# new TODO: Should this be in the helpers section?
reconsider: True
id: alkiln-related config vars
code: |
  alkiln_config_vars = get_config('alkiln') or {}
---
# new TODO: Clarify the comment below—Discuss: consider creating a list that excludes the current dangerous vars. That more permissive list would allow tests to continue even though the tests wouldn't have all the config vars the author wants. Questionable.
# new TODO: Replace `config_vars` with `alkiln_config_vars` everywhere
need:
  - alkiln_config_vars
code: |
  import os
  
  os_env = os.environ.copy()
  dangerous_config_var_names = [var for var in alkiln_config_vars if var in os_env]
  # consider making a list that excludes dangerous vars
  # to be more permissive.
---
# new TODO: Use alkiln_config_vars in here instead
# new TODO: Rename env_vars.
# new TODO: Explore alkiln_config_vars vs. env_vars vs. cusotm_env_vars vs. dangerous_conf...
if: len(dangerous_config_var_names) == 0
code: |
  temp_env_vars = get_config('alkiln') or {}
  temp_env_STRING_VALUES = {key: str(val) for key, val in temp_env_vars.items()}
  env_vars = temp_env_STRING_VALUES
---
id: set custom env vars
reconsider: True
code: |
  import os

  custom_env = dict(
    os.environ,
    SERVER_URL=f'{url_of("root", _external=True)}',  # Discuss: Remove this req?
    _ORIGIN='playground', _ALKILN_ORIGIN='playground',
    _PROJECT_NAME=project_name, _ALKILN_PROJECT_NAME=project_name,
    _USER_ID=f'{user_info().id}', _ALKILN_USER_ID=f'{user_info().id}',
    _TAGS=tag_expression,
    **env_vars
  )
---
# new TODO: Use external custom_env_vars here
need:
  - env_vars
  - sources
  - has_started_tests
id: run alkiln
event: run_alkiln
code: |
  import subprocess
  import signal
  import os

  cmd_exists = has_command("alkiln-run")
  
  # When the process timesout, chrome is closing, but node isn't for about another 50 seconds. That's shorter than the test, which is good, but I'm not sure why it waits so long.

  # if statement for idempotency - ensure tests are only run once
  if not has_started_tests:
    returncode = None
  
    # Ensure that files in the 'sources' folder of all projects are
    # cached in /tmp for S3 and such server configurations so that
    # alkiln can get them there. They should be there for 2hrs at least.
    # It's not possible to just pick one project.
    # From https://github.com/SuffolkLITLab/docassemble-ALDashboard/blob/main/docassemble/ALDashboard/create_package.py#L14-L17
    SavedFile(user_info().id, fix=True, section='playgroundsources')

    sources_arg = f'--sources={ sources }'
    # log(f'□□□ ALKiP sources path: {sources}')
  
    tags = action_argument('tag_expression')

    # Make sure not to pass an empty string for tags as that results in
    # a "@" with no value after it in ALKiln.
    if tags != '':
      to_run = ['/var/www/.npm-global/bin/alkiln-run', tags, sources_arg]
    else:
      to_run = ['/var/www/.npm-global/bin/alkiln-run', sources_arg]
    
    # Prepare the environment variables
    custom_env = dict(
      os.environ,
      SERVER_URL=f'{url_of("root", _external=True)}',
      _ORIGIN='playground',
      _ALKILN_ORIGIN='playground',
      _PROJECT_NAME=action_argument('project_name'),
      _ALKILN_PROJECT_NAME=action_argument('project_name'),
      _USER_ID=f'{user_info().id}',
      _ALKILN_USER_ID=f'{user_info().id}',
      _TAGS=action_argument('tag_expression'),
      # Only need these in GitHub
      REPO_URL="X",
      BRANCH_NAME="X",
      DOCASSEMBLE_DEVELOPER_API_KEY="X",
      **env_vars
    )
    
    # Ensure tests don't re-run, even (especially) if they error
    has_started_tests = True
    
    # Run the tests
    try:
  
      # cwd = os.getcwd()  # "/tmp"
  
      # Should we try/catch this function call?
      process = subprocess.Popen(
        to_run,
        start_new_session=True,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        env=custom_env,
        # Currently "/tmp" is the value da already gives for cwd (in background
        # actions only as far as we can tell), but it may change ¯\_(ツ)_/¯
        cwd="/tmp"
      )

      # Get the process id of the subprocess
      test_run_pid = process.pid
      log( f'□□□ Running ALKiln tests with process ID { test_run_pid }' )

      start_process_wait_time = current_datetime()
      # `.communicate()` `timeout` is in seconds
      # 60 seconds * 60 minutes * 12 hours
      timeout_env_var_name = 'ALKILN_MAX_SECONDS_FOR_PLAYGROUND_TEST_RUN'
      max_run_time = env_vars.get(
        timeout_env_var_name,
        60 * 60 * 12
      )
      
      try:
        # Get output tuple: `(stdout_data, stderr_data)`
        # As a last resort, the processes will timeout
        test_output = process.communicate( timeout=max_run_time )
        returncode = process.returncode
      except subprocess.TimeoutExpired:
        timeout_output = f'■■■ ALKiln Error ALKP0006: the tests run with the pid { test_run_pid } ran for over { date_difference( starting=start_process_wait_time, ending=current_datetime() ).hours } hours. The maximum time allowed is { max_run_time/60/60 } hours. You can change the maximum time by adding the `{ timeout_env_var_name }` value to your config\'s `alkiln` key and giving it a different value.'
        log(timeout_output)
      except Exception as error:
        log('■■■ ALKiln Error ALKP0010: Error while running tests:')
        log(error)

    except Exception as test_run_error:
      import traceback
  
      # We get here even when the sub-processes fail
      log( f'□□□ ALKiP: The test subprocess completed with the returncode { returncode }:' )
      log(test_run_error)
      log("\n".join( traceback.format_exception( test_run_error ) ))

      # Check if the process completed successfully
      # Discuss: what should behavior here be? Where do we catch it
      # lower down?
      # Discuss: Consolidate failure messages into 1 message
      if returncode != None and returncode != 0:
        # Reraise the error
        raise
    
    finally:
      # Always make sure subprocess and its children are terminated
      # Always create output of some kind
      
      # Terminate:
      # You can test this by not stringifying env vars
      try:
        if defined("test_run_pid"):
          os.killpg(os.getpgid( test_run_pid ), signal.SIGTERM)
          # When `.communicate` runs out of time, it doesn't complete
          # the process, so the process still has to finish (by
          # dying, in this case). Make sure the process is fully
          # terminated. Low level interface.
          process.wait()
        else:
          log('■■■ ALKiln Error ALKP0031: The test process ended early and the process ID is missing. Get in touch with us. If you want to experiment, in the past this problem has been caused by interrupted ALKiln installations. It often comes with the message "expected str, bytes or os.PathLike object, not bool". You can try running `rm -rf /var/www/.npm-global/bin` and `rm -rf /var/www/.npm-global/lib`, then restart this interview. To dig even deeper, check the `run_alkiln` block in the ALKilnInThePlayground repository.')
      except ProcessLookupError as already_terminated_error:
        pass
      except Exception as termination_error:
        log('■■■ ALKiln Error ALKP0011: Error while stopping tests:')
        log(termination_error)
        
      # Output:
  
      # https://github.com/SuffolkLITLab/docassemble-AssemblyLine/blob/main/docassemble/AssemblyLine/al_document.py#L1275-L1284
      # https://github.com/SuffolkLITLab/docassemble-ALDashboard/blob/main/docassemble/ALDashboard/data/questions/compile_bootstrap.yml
      if defined('test_output'):
        stdout = test_output[0].decode('utf-8')
        stderr = test_output[1].decode('utf-8')

      return_code_msg = ''
      if showifdef("returncode", "None") == None:
        # Discuss: Add link to worker log?
        return_code_msg = """The test process terminated before finishing
  (the returncode was `None`). Check your worker.log
  and feel free to get in touch with us.\n"""
      elif showifdef("returncode", "None") != 0:
        # Discuss: Add link to worker log?
        return_code_msg = """The test process finished, but it ran into 
  an error. We hope there is more information on this
  page or in your worker.log.\n"""

      # Discuss: If return code None, link to logs? Enough links around?
      output_main = '\n'.join( text for text in [ return_code_msg, showifdef('timeout_output', ''), showifdef('stdout', ''), showifdef('stderr', '') ] if text )

      log(f'□□□ ALKiln test run output:\n{ output_main }' )
      
      background_response( output_main )
---
code: |
  has_started_tests = False
---
prevent going back: True
event: waiting_screen
reload: True
question: |
  Hang tight, ALKiln is running the tests.
subquestion: |
  <div class="spinner-container d-flex justify-content-center">
  <div class="spinner-border" role="status">
    <span class="visually-hidden">Running tests...</span>
  </div>
  </div>

  While tests are running try to avoid:
  
  - Editing this project
  - Saving a python module
  - Pulling or uploading a package with a python module
  - Causing the server to reload, restart, or stop
  
  Otherwise, tests might fail and you'll have to rerun them.

  This screen will reload about every 10 seconds until the tests are done (depending on your server speed).
  
  **Elapsed time: ${ str(test_time.delta) }**[BR]
  (Updates about every 10 seconds depending on your server)

# revoke tests
action buttons:
  - label: Stop tests early
    action: stop_tests_early
    icon: window-close
    color: danger
---
event: stop_tests_early
code: |
  stopped_early = True
  test_run_output.revoke()
---
code: |
  stopped_early = False
---
reconsider: True
code: |
  # Deliberately explicit about the end time
  test_time = date_difference( ending=current_datetime(), starting=test_start_time )
---
code: |
  test_start_time = current_datetime()
---
need:
  - folder_name
  - folder_path
code: |
  test_data = get_files_html( folder_name, folder_path )
  files_html = test_data["html"]
  test_run_outcome = test_data["outcome"]
  if files_html == None:
    file_problem = True
  _debug(f'file_problem: { file_problem }')
  run_get_files_html = True
---
# Does this absolutely need to be separate? Do we at times
# want to avoid calling get_files_html()?
code: |
  file_problem = False
---
# new TODO: remove irrelevant `need`s
# new TODO: Change 007: "error making files output" type of thing
# new TODO: Change second 007 to something more relevant too
# new TODO: Discuss using root_path instead of "/tmp" with cwd everywhere
need:
 - _log
 - _debug
 - zip_name_no_ext
 - zip_name
 - get_file_html
code: |
  import os
  import subprocess
  
  def get_files_html(folder_name_, folder_path_):
    '''Return html to show artifacts files and artifacts zip.'''

    test_run_outcome = None
  
    if folder_path_ is None:
      _log('■■■ ALKiP Error ALKP0007: error zipping artifacts folder at "{ folder_path_ }" to { zip_path }:')
      return {"html": None, "outcome": None}
    
    html = ''
    
    _debug('💡 ALKP0040 ALKiln will try to save the artifacts zip with the name ' + zip_name_no_ext )

    # TODO: does cwd control where zip is saved or where subprocess
    # looks for the folder?
    # zip_name_no_ext "the_zip", folder_name_ "the_folder"
    # folder_path_ "/tmp/the_folder"
    zip_process = subprocess.run(['zip', '-r', '-v', f'{ zip_name_no_ext }', f'{ folder_name_ }'], cwd="/tmp", check=False, capture_output=True)

    if zip_process.stdout:
      _debug('💡 ALKiP NOTE ALKP0042: zipped artifacts folder. stdout:')
      _debug( zip_process.stdout )

    zip_path = get_zip_path()["path"]
  
    # Zip section
    html += '<div class="section zip">\n'

    # Folder path was fine, but unable to make zip
    if zip_process.returncode != 0:
      _log('■■■ ALKiP Error ALKP0007: error zipping artifacts folder at "{ folder_path_ }" to { zip_path }:')
      _log(zip_process.stderr.decode("utf-8"))
      html += '<span>ALKilnInThePlayground was unable to create a zip file for the artifacts. See your <a target="_blank" href="${url_of("root", _external=True)}/logs?file=docassemble.log">docassemble.log</a> for more details.</span>\n'

      # There is technically no reason to stop here since the folder seems
      # to exist and we can hope to show some output from there.
  
    else:
      _debug(f'ALKP0018 ALKiln saved the zip file correctly to "{ zip_path }".')
      zip_da_file = DAFile()
      zip_da_file.initialize( filename=zip_name )
      zip_da_file.copy_into( zip_path )
      zip_da_file.commit()
    
      html += f"""
        <div>{ action_button_html(zip_da_file.url_for(), label="Download all files and folders ALKiln created", color="primary", size="md", icon="file-zipper", new_window=True, classname="zip") }</div>
  
        <div class="to_console">
          <a href="#console" markdown="1" class="btn btn-secondary" type="button">:arrows-down-to-line: Jump down to the full console logs</a>
        </div>
      """
  
    html += '</div>\n'  # ends zip section
    
    # collect top-level names and paths.
    top_dirs = []
    top_files = []
    top_other = []
    # A bit faster than other methods, though that doesn't matter much here so far. https://stackoverflow.com/a/62478211/14144258
    with os.scandir( folder_path_ ) as scan:
      for dir_item in scan:
        _debug(f'Scanning { folder_path_ }/{ dir_item.name }')
        if dir_item.is_file():
          top_files.append(dir_item)
        elif dir_item.is_dir():
          top_dirs.append(dir_item)
        else:
          top_other.append(dir_item)

    # ====== "Root" level directories ======
    top_dirs.sort(key=lambda dir: dir.name)
  
    # ====== "Root" level files section ======
    html += '<div class="section quick_view">\n'
    html += '<h2>Quick view</h2>\n'
    html += '<aside>Reports, error screenshots, etc.</aside>\n'
    html += '<div class="output card card-body">\n'

    # Show files that are for the all the tests combined
    # This includes error screenshots
    summary_images_html = ''
    summary_other_files_html = ''
    report_html = ''
    summary_files_exist = False
    top_files.sort(key=lambda file: file.name)
    for file in top_files:
      file_html = get_file_html(name=file.name, path=file.path)

      # Non-summary files
      # Discuss: should these be summary files too? Should
      # "debug_log" be listed if "report" is missing?
      if file.name == 'debug_log.txt':
        with open(file.path, 'r') as report:
          content = report.read()
        if 'ALK0099' in content:
          test_run_outcome = 'failed'
        elif 'ALK0055' in content:
          test_run_outcome = 'unexpected'
        elif 'ALK0054' in content:
          test_run_outcome = 'passed'
      elif file.name == 'temp_unexpected_results_debug_log.txt':
        # TODO: Only skip this file if the "unexpected results" file did get created at the end
        continue
      # TODO: Add "unexpected results" file? Above or below
      # the report file?
      # Discuss: (ALKiln) Output content in general

      # Summary files
      else:
        summary_files_exist = True
        if file.name.endswith('.jpg'):
          summary_images_html += file_html
        elif file.name == 'report.txt':
          report_html = file_html
        else:
          summary_other_files_html += file_html

    if summary_files_exist:
      html += f"""
          <ul class="text_files">
            {report_html}
            {summary_other_files_html}
          </ul>
          """
      if summary_images_html != '':
        html += f"""
          <hr>
          <ul class="images">
            {summary_images_html}
          </ul>
          """
    else:
      html += """
        <div class="no_output">
          <p>ALKiln found no summary files (like report.txt). Maybe no tests ran. Some questions to ask:</p>
          <ul>
            <li>Does the console output show that the tests ran "0 scenarios"?</li>
            <li>Does your Sources folder contain files ending in ".feature"?</li>
            <li>Does <a href="#report">the console output at the bottom of this page</a> show that ALKiln ran into an error before it could run any of your tests?</li>
            <li>If you used a <a href="https://assemblyline.suffolklitlab.org/docs/components/ALKiln/writing/#tags:~:text=Tag%20expression-,What%20tests%20run%3F,-%40likes_bears">tag expression</a>, do you have a typo in your tag expression?</li>
          </ul>
        </div>
        """
    
    # End summary files items
    html += '</div>\n'
    # End summary files section
    html += '</div>\n'

    # ====== Nested dirs output ======
  
    # ====== Start all Scenarios ======
    html += '<div class="section scenarios">\n'
    html += '<h2>Scenarios</h2>\n'
    
    # For each Scenario
    for dir in top_dirs:
  
      html += '<div class="output card card-body scenario">\n'
      html += f'<h3>Scenario: {dir.name}</h3>\n'
      
      # Get the files in that Scenario
      for root_path, dir_names, file_names in os.walk(f'{dir.path}'):
        file_names.sort()
        
        # TODO: organize files by type: report, error, screenshots, downloaded. Maybe by timestamp instead of by name?
        text_files_html = ''
        images_html = ''
        templates_html = ''
        other_files_html = ''
        
        if len(file_names) == 0:
          html += '<div class="no_files">ALKiln stored 0 artifact files for this Scenario.</div>'
        
        for file_name in file_names:
          abs_path = os.path.abspath(os.path.join(root_path, file_name))
          file_html = get_file_html(name=file_name, path=abs_path)
          if file_name.endswith('.txt'):
            text_files_html += file_html
          elif file_name.endswith('.jpg'):
            # Discuss: carrousel for error screenshots section?
            # Discuss: sym link to images instead of duplicate?
            images_html += file_html
          elif file_name.endswith('.pdf') or file_name.endswith('.docx'):
            # TODO: need more flexibility for other types of downloaded files
            templates_html += file_html
          else:
            # Not sure what these'll be
            other_files_html += file_html
        
        if text_files_html != '':
          html += f'<ul class="text_files">\n{text_files_html}\n</ul>\n'
        # Downloaded pdfs and docxs
        if templates_html != '':
          html += '<hr>\n'
          html += f'<ul class="templates">\n{templates_html}\n</ul>\n'
        if images_html != '':
          html += '<hr>\n'
          # Ordered list because timing creates an order that does matter. Moreso once we have story table screenshots
          html += f'<ol class="images">\n{images_html}\n</ol>\n'
        if other_files_html != '':
          html += '<hr>\n'
          html += f'<ul class="other_files">\n{other_files_html}\n</ul>\n'
      # Ends one Scenario
      html += '</div>\n'
  
    else:
      html += '<div class="output card card-body scenario">\n'
      html += '<div class="no_output">ALKiln found no output files.</div>\n'
      html += '</div>\n'
      
    # End all Scenarios
    html += '</div>\n'
    
    return { "html": html, "outcome": test_run_outcome }
---
id: non-feature files
code: |
  def get_file_html(name='', path=''):
    # Show a DAFile for each file
    da_file = DAFile()
    da_file.initialize(filename=f'{space_to_underscore(name)}')
    da_file.copy_into( path )
    da_file.commit()
    
    if name.endswith('.txt'):
      html = f'<li>\n{name} (<a target="_blank" href="{da_file.url_for()}">tap to see raw text <i class="fas fa-external-link"></i></a>)\n</li>\n'
    else:
      # Assumes a file that can be shown with a thumbnail image
      da_file.set_alt_text(f'The thumbnail image for {name}.')
      html = f'<li class="thumbnail">\n'
      html += f'<span><span>{name}</span> '
      html += f'(<a target="_blank" href="{da_file.url_for()}">tap to see file <i class="fas fa-external-link"></i></a>)'
      html += f'</span>\n'
      html += f'<div><a target="_blank" href="{da_file.url_for()}">{da_file}</a></div>\n'
      html += f'</li>\n'
    
    return html
---
# new TODO: Delete `need`s except `folder_path`
# new TODO: Move to files helper section
id: remove/delete files
need:
  - _log
  - _debug
  - folder_name
  - folder_path
code: |
  # Let this block run regardless just in case it can manage to clean
  # something up
  
  zip_path = get_zip_path()["path"]
  
  import os
  try:
    os.remove( zip_path )
  except Exception as error:
    _log(f'🖊️ ALKiln Note ALKP0008: skipped removing old "{ zip_path }"')
    _debug(error)
  
  import shutil
  try:
    shutil.rmtree( folder_path )
  except Exception as error:
    _log(f'🖊️ ALKiln Note ALKP0009: skipped removing "{ folder_path }"')
    _debug(error)
  
  # https://stackoverflow.com/a/32949415/14144258
  import glob
  # Remove leftover puppeteer stuff if it exists (e.g. if the user
  # stopped the tests early)
  # https://github.com/puppeteer/puppeteer/issues/6414
  sub_folders_list = glob.glob('tmp/puppeteer_dev_chrome_profile*')
  for sub_folder in sub_folders_list:
    shutil.rmtree(sub_folder)
  
  remove_tmp_files = True
---
# new TODO: Remove block
code: |
  import re
  
  def get_zip_name(folder_name):
    return re.sub("( )+", "_", folder_name)
---
# new TODO: Remove bottom text "couldn't delete artifacts"
prevent going back: True
event: show_output
question: |
  ALKiln output
subquestion: |

  <div id="alkiln_test_output">
  
  % if stopped_early:
  <p class="alert alert-warning">
  Warning: You stopped the tests early. Below is the information the tests collected so far.
  </p>
  % endif
  
  <div class="section">
  <div class="version">
  Ran with ALKiln version <b>${ get_installed_version() }</b>[BR]
  Ran with tag expression "${ tag_expression }"
  </div>
  <div class="elapsed_time">
  Elapsed time: <b>${ str(date_difference( ending=end_time, starting=test_start_time ).delta) }</b>
  </div>
  
  </div>

  % if artifacts_errored:
  ${ setup_error_html }
  % endif
  
  % if file_problem:
  <div class="alert alert-danger" markdown="1">
  % if config_path is None:
  ${ config_path_problem }
  % endif

  % if folder_path is None:
  ${ folder_path_problem }
  % endif

  % if get_zip_path()["path"] is None:
  ${ get_zip_path()["problem"] }
  % endif

  The installed version of ALKiln did not create any files. Your <a target="_blank" href="${url_of('root', _external=True)}/logs?file=worker.log"> worker.log</a> or your <a target="_blank" href="${url_of('root', _external=True)}/logs?file=docassemble.log">docassemble.log</a> might have more information.
  </div>

  % else:
  ${ files_html }
  % endif

  ${ test_output_template }
  </div>

  ${ "" if remove_tmp_files else "" }
buttons:
  - Run new tests: new_session
---
code: |
  test_run_outcome = None
---
need:
  - folder_name
template: test_output_template
content: |
  <div class="console_output">
  <div class="section">
  <h2 id="console">Console output</h2>
  <pre>Temp console content during transition to ravioli</pre>
  </div>
  </div>
comment: |
  <div class="console_output">
  <div class="section">
  <h2 id="console">Console output</h2>
  <pre><code>
  % if no_output or test_run_output.get() is None or test_run_output.get() == 'None':
  No console output
  
  Your <a target="_blank" href="${url_of('root', _external=True)}/logs?file=worker.log">worker.log</a> might have more information.
  % else:
  ${ test_run_output.get() }
  % endif
  </code></pre>
  </div>
  </div>
---
template: setup_error_html
content: |
  <div class="setup_error alert alert-danger">
  <p>Test setup errored. Here are examples of why this can happen:</p>
  <ul>
  <li>Invalid ".feature" files</li>
  <li>An internal ALKiln error.</li>
  </ul>
  </br>
  <p>You might see console output below and you might also find more information in your <a target="_blank" href="${url_of('root', _external=True)}/logs?file=worker.log">worker.log</a> or your <a target="_blank" href="${url_of('root', _external=True)}/logs?file=docassemble.log">docassemble.log</a>.</p>
  </div>
---
# Filepaths
---
need:
  - get_existing_path
code: |
  temp_config_path = get_existing_path( "runtime_config.json" )
  if temp_config_path is None:
    config_path_problem = 'No "runtime_config.json" file exists.'
    _log(f'🤕 ALKiP Error ALKP0033: { config_path_problem }')
  config_path = temp_config_path
---
id: default config_path_problem
code: |
  config_path_problem = ''
---
# new TODO: Reword comment—Need folder_name to try various folder_path values. Need various values for compatibility with old ALKiln versions. See `get_existing_path()` notes
# Need folder_name to try various folder_path values for
# compatibility. See `get_existing_path()` notes
id: artifacts folder name
need:
  - _debug
  - config_path
code: |
  import os
  
  if config_path is None:
    temp_folder_name = 'no config'

  else:
    with open( config_path ) as config_text:

      try:
        temp_folder_name = json.load( config_text ).get('artifacts_path', 'no value')
  
      except Exception as config_load_error:
        temp_folder_name = 'no json'
        _log(f'🤕 ALKiP Error ALKP0035: Error loading json from config file at "{ config_path }":')
        _log( config_load_error )
  
      if temp_folder_name == 'no value':
        _log(f'🤕 ALKiP Error ALKP0034: Config file at "{ config_path }" has no "artifacts_path" value.')

  _debug(f'temp_folder_name: { temp_folder_name }')
  root_path = os.path.dirname( temp_folder_name )
  _debug(f'root_path: { root_path }')
  folder_name = os.path.basename( temp_folder_name )
  _debug(f'folder_name: { folder_name }')
---
# new TODO: fix: "folder_path tries different locations till it finds the real one"
# folder_name tries various folder_path values for
# compatibility. See `get_existing_path()` notes. Used to get
# folder to make zip and to delete folder.
need:
  - _log
  - get_existing_path
  - folder_name
code: |
  temp_folder_path = get_existing_path( dir_name=folder_name )
  if temp_folder_path is None:
    folder_path_problem = f'Unable to find artifacts folder at "{ folder_name }".'
    _log(f'🤕 ALKiP Error ALKP0039: { folder_path_problem }')
  folder_path = temp_folder_path
---
id: default folder_path_problem
code: |
  folder_path_problem = ''
---
# Need zip_name_no_ext to save the new zip file without ".zip"
need:
  - very_safe_name
  - folder_name
code: |
  _debug( f"very_safe_name( folder_name ): {very_safe_name( folder_name )}" )
  zip_name_no_ext = very_safe_name( folder_name )
---
# Need zip_name to avoid duplicating adding ".zip" to get
# correct zip_path value and to name zip file.
need:
  - zip_name_no_ext
code: |
  _debug( f"zip_name_no_ext .zip: { zip_name_no_ext }.zip" )
  zip_name = f"{ zip_name_no_ext }.zip"
---
# new TODO: Describe what it's used for - to put contents into the DAFile once the zip is stored wherever it is stored.
# new TODO: "get_zip_path tries..."
# zip_path tries various zip_path values for compatibility
# See `get_existing_path()` notes. Need zip_path to get zip
# DAFile and to remove zip
need:
  - _debug
  - zip_name
code: |
  def get_zip_path():
    zip_path_problem = ''
    zip_path = get_existing_path( file_name=zip_name )
    if zip_path is None:
      zip_path_problem = f'Unable to find a file called "{ zip_name }".'
      _log(f'🤕 ALKiP Error ALKP0041: { zip_path_problem }')
    _debug( f"zip_path: { zip_path }" )
    return { "path": zip_path, "problem": zip_path_problem }
---
# Older versions of ALKiln's config named relative paths
# Newer versions have absolute paths
need:
  - _debug
code: |
  def get_existing_path( dir_name=None, file_name=None ):
    if dir_name != None:
      return get_existing_dir_path( dir_name )
    if file_name != None:
      return get_existing_file_path( file_name )
    _debug("🖊️ ALKP0036: `get_existing_path` got no valid arguments")
    return None
---
need:
  - _log
  - root_path
code: |
  import os
  
  def get_existing_dir_path( dir_name ):
    """
    """
    # if "/tmp/the_dir"
    if os.path.exists( dir_name ):
      return dir_name
  
    # if "the_dir"
    if os.path.exists(f'{ root_path }/{ dir_name }'):
      return f'{ root_path }/{ dir_name }'

    # if "the_dir" and root_path broken, make a last ditch effort
    if os.path.exists(f'/tmp/{ dir_name }'):
      return f'/tmp/{ dir_name }'

    _log(f'🖊️ ALKP0037: Found no "{ dir_name }", "{ root_path }/{ dir_name }", or "/tmp/{ dir_name }" directory')
    return None
---
need:
  - _log
  - root_path
code: |
  import os
  
  def get_existing_file_path( file_name ):
  
    if os.path.isfile( file_name ):
      return file_name
    if os.path.isfile(f'{ root_path }/{ file_name }'):
      return f'{ root_path }/{ file_name }'
    if os.path.isfile(f'/tmp/{ file_name }'):
      return f'/tmp/{ file_name }'
  
    _log(f'🖊️ ALKP0038: Found no "{ file_name }", "{ root_path }/{ file_name }", or "/tmp/{ file_name }" file')
    return None
---
---
id: very strict name sanitization
code: |
  def very_safe_name( uncertain_str ):
    return re.sub(r"[^A-z0-9_]", "_", uncertain_str)
---
---
id: check command existence
need:
  - _debug
code: |
  import os
  def has_command( bin_name ):
    cmd_exists = os.path.isfile(f"/var/www/.npm-global/bin/{ bin_name }")
    _debug(f"{ bin_name } exists? { cmd_exists }")
    return cmd_exists
---
---
code: |
  import time
  def timey():
    return time.time()
---
---
code: |
  def _log( to_log, where="log" ):
    log( to_log, where )
    if where != "console":
      log( to_log, "console" )
    return ''
---
need:
  - debugging
code: |
  def _debug( to_log, where="log" ):
    if debugging:
      try:
        log( repr(to_log), where )
        if where != "console":
          log( repr(to_log), "console" )
      except:
        try:
          log( to_log, where )
          if where != "console":
            log( to_log, "console" )
        except:
          pass
    return ''
---
code: |
  debugging = alkiln_config_vars.get('alkip_debug', False)
---
---
# Default
code: |
  root_path = "/tmp"
---